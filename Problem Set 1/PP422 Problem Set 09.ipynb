{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions {-}\n",
    "\n",
    "1. Download the provided jupyter notebook file to your computer.\n",
    "2. Write all your answers and code into this notebook file.\n",
    "3. When your work is completed, export your notebook to an HTML file.\n",
    "4. Submit your HTML file and a copy of the notebook to the assignment page on Moodle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification {-}\n",
    "\n",
    "### Your Information {-}\n",
    "\n",
    "Your Last Name: Siddique\n",
    "\n",
    "Your First Name: Muhammad Saad\n",
    "\n",
    "\n",
    "### Group Members (list any classmates you worked with on this problem set) {-}\n",
    "\n",
    "Your Group Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 0 - Setting up a GitHub Repo for PP422 Work {-}\n",
    "\n",
    "At the end of AT we introduced GitHub and some of its capabilities. To allow you to continue practicing with GitHub, I recommend you begin saving your PP422 Problem Set work in a repository and that you get in the habit of committing / pushing changes to your problem sets as you work on them.\n",
    "\n",
    "The rest of this problem walks you through this process. Try to create this repository structure for your course materials but do not worry too much if you run into problems as having this fully completed is not required at this time. **I recommend you try to follow the steps below for no more than 1 hour, and after that skip to later problems and speak with course staff to help complete your setup.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a New Repository for PP422 {-}\n",
    "\n",
    "If you are more experienced with Git, you may wish to initialize a new repository directly from your local folders (see some instructions [here](https://docs.github.com/en/migrations/importing-source-code/using-the-command-line-to-import-source-code/adding-locally-hosted-code-to-github)). \n",
    "\n",
    "If you are new to Git/GitHub, it is far easier to create the repository first and then upload your local folders later. The following instructions walk you through this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New Repository on GitHub {-}\n",
    "\n",
    "Navigate to your GitHub page and create a new repository (you can find the GitHub guide for this [here](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-new-repository)). \n",
    "\n",
    "Note, you may name this repository anything you like (e.g. `PP422_Problem_Sets`). In the lesson at the end of AT we were careful to match the repository name to our account name, but that was only so we could leverage the automatic website creation provided by GitHub pages. We will not need that for all your repositories.\n",
    "\n",
    "When creating the repository:\n",
    "\n",
    "1. Set the visibility to Private\n",
    "2. Add a README file \n",
    "\n",
    "You will not need to add any .gitignore files or license at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the Steps from Autumn Term Lecture 20  to Clone this Repository Locally {-}\n",
    "\n",
    "You can now follow the same steps from the AT class to clone this repository locally to wherever you save your course materials. The quickstart guide for doing this in VS Code is available [here](https://code.visualstudio.com/docs/sourcecontrol/quickstart).\n",
    "\n",
    "To summarise:\n",
    "\n",
    "1.  Open the 'Explorer' tab on the left-hand side of VS Code\n",
    "2.  In your internet browser, navigate to your newly created repository. Under the `Code` tab, select `Local`, select and copy the SSH URL\n",
    "3.  Return to your VS Code tab and Select the 'Clone Repository' option and paste the URL for your repository copied above\n",
    "4.  A window should open asking where you want to clone this repository locally. Navigate to wherever you store your PP422 materials.\n",
    "\n",
    "After completing Step 4 in the above process, you should now have a folder on your computer associated with this GitHub repository. You can then move (copy and paste) all your existing PP422 material into this folder. After doing this, you can open a terminal window in VS code and use the following commands to push this content to your repository.\n",
    "\n",
    "1. `pwd` - check your current working directory. Ensure it is set to the new GitHub folder you just created. Otherwise, you may use the left-hand panel of VS code in the Explorer tab to Open this folder location (or you can use the `cd` terminal command to change your directory to the desired location)\n",
    "\n",
    "2.  `git status` This command will tell you the current status of your location. If you have copied new files into this folder, it should show these new additions as changes not staged for commit. If you get a message about \"not a git repository\" it means your current working directory does not match the GitHub folder you created above\n",
    "\n",
    "Then, you can run the following three commands to add / commit / push all of these new files to your repository.\n",
    "\n",
    "3.  `git add .` \n",
    "4.  `git commit -m \"Initial commit\"`\n",
    "5.  `git push`\n",
    "\n",
    "If everything went well, if you return to your internet browser and refresh your GitHub page, it should be updated with your PP422 materials.\n",
    "\n",
    "You can now work from this folder on your problem sets and add / commit / push updates as you work through them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - k-NN Prediction on Caravan Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Caravan data](https://islp.readthedocs.io/en/latest/datasets/Caravan.html) set contains 5,822 customer records made available from a Dutch company with demographic features and purchasing behavior. Specifically, the `Purchase` variable records whether a given individual elected to purchase a caravan insurance policy. This exercise asks you to predict this purchasing behavior via k-NN.[^1]\n",
    "\n",
    " Read in the provided `Caravan.csv` file and then answer the following questions.\n",
    "\n",
    " [^1]: Adapted from ISLP Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-0: Textbook Reading {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key background reading on k-NN is provided in the Winter Term Week 1 Reading List from the Introduction to Statistical Learning Python (ISLP) course textbook. If you would like to review this model in more detail before attempting these problems please consult:\n",
    "\n",
    "1. ISLP Chapter 2.2.3, subheading on k-NN\n",
    "2. ISLP Chapter 3.5: Comparison of Linear Regression with k-NN\n",
    "\n",
    "Additionally, you may wish to review the sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) and [user guide (1.6.2)](https://scikit-learn.org/stable/modules/neighbors.html#classification) for the `KNeighborsClassifer` in addition to the code presented in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-A: Initial Exploration {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data set. Focusing on the `Purchase` variable, report the percentage of respondents who did and did not purchase insurance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-B: Pre-processing the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the variable measurements in this data set are not on the same scale, which would make it difficult to accurately calculate the distances needed to apply k-NN. Complete the following pre-processing steps:\n",
    "\n",
    "1. Standardize your variables\n",
    "2. Isolate the `Purchase` variable which we will aim to predict from the rest of the data.\n",
    "\n",
    "To standardize the columns, you may find it useful to use the sklearn `StandardScaler()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-C: Estimating a k-NN Model {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the above pre-processing, complete the following steps:\n",
    "\n",
    "1. Randomly split your data into a training and testing sample using the `train_test_split()` function from the sklearn library. Set the size of your testing sample to be 30% of the full data. Use the `random_state=422` to make your split replicable\n",
    "2. Use the `KNeighborsClassifier()` to fit a k-NN model, setting `n_neighbors=1`\n",
    "3. Use your model fit in Step 2 to obtain predictions for the testing data\n",
    "4. Calculate and report the accuracy of this model (that is, what percentage of observations in the testing sample were correctly classified)\n",
    "5. Report the \"confusion matrix\" for this model on the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D: Interpreting the Accuracy and Confusion Matrix {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your results above, does this seem to be a good classifier? Explain your reasoning in language a non-technical audience member could understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-E: Different Values of k {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above questions, you fit a model matching to the single nearest neighbor (k=1). Model performance could be improved by considering different measures of $k$. Using a for-loop, replicate your above code for all values of $k$ between $1$ and $10$. Which value of $k$ produces the greatest accuracy in the testing data. Report the confusion matrix for this value of $k$ on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-F: Accuracy in the Training Sample {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above analysis you examined accuracy for prediction in the testing data. For what value of $k$ would you expect accuracy to highest within the _training_ data. Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-G: Cross-validation {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your above analysis you examined the error rate as a function of the number of nearest neighbors $k$. You only had a single estimate for the error rate for each $k$, so the selected value of $k$ could have produced the lowest error rate due to random sampling error. One way to address this is through cross-validation to obtain a range of estimates for the error rate for each $k$. Read the documentation for the `cross_val_score()` function in `sklearn`, which is available [here](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics).\n",
    "\n",
    "Use the `cross_val_score()` function to implement 5-fold cross-validation (`cv=5`) on the _training data_ to determine the optimal value of $k$. Then apply this value of $k$ to fit a model on the __entire__ training data and generate new predictions for the testing data based on this model. Report your new accuracy and how it compares to your earlier results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Reading on k-NN to Impute Missing Values (OPTIONAL) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another practical usage of k-NN is to _impute_ missing values. To date in this course we have primarily dropped missing values before conducting our analysis. However, you can think of missing values as another type of prediction problem. For a variable with missing values, we observe this variable for some observations in our data set, so we could use those observations where we have data as a training set to try to predict (impute) what the missing values may be for other observations.\n",
    "\n",
    "k-NN is one choice for this type of imputation, and sklearn has a specific imputer of this type which you can read about [here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer).\n",
    "\n",
    "However, when handling missing data, you must think carefully about __why__ the data may be missing in the first place. Unlike a random training / testing split of the data, missing values may not be randomly assigned, and the degree to which they are randomly assigned determines which methods are appropriate for handling these cases.\n",
    "\n",
    "Three general types of missing data are:[^2]\n",
    "\n",
    "1. __Missing Completely at Random (MCAR)__: Missing values are uncorrelated with observed variables in the data. This is the easiest case to solve and many imputation methods are viable, including simple mean / median imputation. Missing values are unlikely to bias analysis as they are uncorrelated with your measures.\n",
    "2. __Missing at Random (MAR)__: Missing values depend on observed variables in the data set. Missing values can bias your analysis if untreated. Simple mean / median imputation is inappropriate as missing values are related to other variables, but model based imputation (like k-NN) can adjust for these correlations.\n",
    "3. __Missing Not at Random (MNAR)__: Missing values are correlated with outcomes you may care about, but are not correlated with observed values in the data set. Imputation is typically inappropriate here and subject matter knowledge is needed to understand the cause and consequences of missing data.\n",
    "\n",
    "For a useful summary of some of these considerations, see [Bhaskaran and Smeeth (2014)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4121561/#:~:text='Missing%20completely%20at%20random'%20means,missing%20and%20observed%20blood%20pressures.).\n",
    "\n",
    "[^2]: Chen, Cornwall, Rubin (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Assigned Readings {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-A: Big Data and Machine Learning in Health Care {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the provided piece by Beam and Kohane (2018). This article describes a _\"machine learning spectrum.\"_ Explain what the authors mean by this term. Also describe some of the costs and benefits of using approaches higher on this machine learning spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-B: A Guide to Solving Social Problems with Machine Learning {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the provided piece by Kleinberg, Ludwig and Mullainathan (2016) - A Guide to Solving Social Problems with Machine Learning. The authors note \"Current practice is to report how well one's algorithm predicts only among those cases where we can observe the outcome.\" Explain why this is a problem. State an example of a policy area/application (besides the ones raised in the article) you feel would be susceptible to this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-C: Any Other Reactions to these Articles (OPTIONAL) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any other thoughts on these articles, please share them [here](https://moodle.lse.ac.uk/mod/questionnaire/view.php?id=1809682)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Engagement Plan Review and Check-in {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the Autumn Term, I asked you to outline how you planned to engage with course content. Please provide a reflection on how you have progressed towards this plan at the following [survey](https://moodle.lse.ac.uk/mod/questionnaire/view.php?id=1809684). \n",
    "\n",
    "After completing this survey, if you have not already met with course staff (Andrew or Casey) during office hours in the AT, I also ask that you reserve at least one 15-minute office hour slot during the initial weeks of the term to discuss your plans and any questions you may have for this term and next year.\n",
    "\n",
    "I have added additional availability on Student Hub for the week of January 26, and please email us if none of the available times work for your schedule.\n",
    "\n",
    "When you have finished this survey and reserved office hours, write 'Done' in the below box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write 'Done' Here:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: What does your AI know about you? (OPTIONAL) {-}\n",
    "\n",
    "I am curious what insights your AI may know about you. If you have been working consistently with an AI tool (e.g. Claude, ChatGPT) for problem sets in this course, it may be able to detect patterns in your workflow. It also may see your earlier errors and work flow which we as course staff do not see in your final submissions.\n",
    "\n",
    "In your AI project space for this course, try asking your AI to reflect on your strengths / weaknesses. Here is a variation of a prompt I used to start the new year.\n",
    "\n",
    ">   We have had many chats across several projects I have created. I am curious what your assessment of me is from these interactions. Based on our conversations, are there any weaknesses or repeated mistakes you see me making that I should focus on trying to improve? Can you propose any study plan or concrete steps I should take to improve?\n",
    "\n",
    "I am curious to know if you find this reflection helpful / unhelpful. I have created an anonymous survey linked on the Moodle page [here](https://moodle.lse.ac.uk/mod/questionnaire/view.php?id=1902281) for you to share any of the AI feedback, recommendations, or things you agree / disagree with it about."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
